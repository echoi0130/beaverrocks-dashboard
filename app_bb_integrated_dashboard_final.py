import os
import json
import re
import html
from typing import Dict, Any, List, Tuple, Optional

import pandas as pd
import streamlit as st

import requests
import circlify
import plotly.express as px
import plotly.graph_objects as go


# =========================================================
# Fixed file names
# =========================================================
BUBBLE_CSV = "year_tag_counts_all_ranked.csv"
ELEMENTS_CSV = "year_element_mentions_with_examples_type8.csv"
GAMES_CSV = "year_game_top10_with_examples.csv"
BEAVERROCKS_URL = "https://beaverrocks.com/"
FULLTEXT_CSV = "burningbeaver_final_fulltext.csv"
OFFICIAL_GAMES_CSV = "BB2022_2025_games.csv"
OFFICIAL_ELEMENTS_CSV = "BB2022_2025_elements_final.csv"


# =========================================================
# Page
# =========================================================
st.set_page_config(page_title="Burning Beaver (Beaver Rocks) â€” Dashboard", layout="wide")

CSS = """
<style>
@import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard@v1.3.9/dist/web/static/pretendard.css');

:root{
  --bb-red: #E53935;
  --bb-orange: #FF6D00;
  --bb-bg: #FFF5EF;
  --bb-card: rgba(255,255,255,0.94);
  --bb-border: rgba(0,0,0,0.10);
  --bb-text: #171717;
  --bb-muted: rgba(23,23,23,0.66);
}

html, body, [class*="css"], [data-testid="stAppViewContainer"]  {
  font-family: "Pretendard", system-ui, -apple-system, "Segoe UI", Roboto, Arial, "Apple Color Emoji", "Segoe UI Emoji", "Noto Color Emoji", sans-serif !important;
  color: var(--bb-text);
  font-size: 18px;
}

[data-testid="stAppViewContainer"]{
  background: radial-gradient(1200px 600px at 10% 0%, rgba(255,109,0,0.10), transparent 60%),
              radial-gradient(900px 500px at 90% 10%, rgba(229,57,53,0.10), transparent 55%),
              linear-gradient(180deg, var(--bb-bg), #FFFFFF 45%);
}

.hero{
  padding: 16px 18px;
  border: 1px solid var(--bb-border);
  border-radius: 18px;
  background: linear-gradient(135deg, rgba(255,109,0,0.20), rgba(229,57,53,0.16));
  box-shadow: 0 10px 24px rgba(0,0,0,0.05);
  margin-bottom: 10px;
}
.hero h1{
  margin: 0;
  font-size: 32px;
  font-weight: 900;
  letter-spacing: -0.3px;
}
.hero .sub{
  margin-top: 8px;
  color: var(--bb-muted);
  font-weight: 800;
  font-size: 16px;
}
.chips{
  margin-top: 10px;
  display: flex;
  flex-wrap: wrap;
  gap: 8px;
}
.chip{
  display: inline-flex;
  align-items: center;
  gap: 8px;
  padding: 7px 11px;
  border-radius: 999px;
  border: 1px solid var(--bb-border);
  background: rgba(255,255,255,0.78);
  font-size: 13px;
  font-weight: 900;
}
.chip a{ color: inherit; text-decoration: none; }
.chip:hover{ transform: translateY(-1px); transition: 120ms ease; }

.card{
  border: 1px solid var(--bb-border);
  border-radius: 18px;
  background: var(--bb-card);
  box-shadow: 0 10px 22px rgba(0,0,0,0.04);
  padding: 12px 14px;
}
.kicker{
  color: var(--bb-muted);
  font-size: 13px;
  font-weight: 900;
  margin-bottom: 6px;
}
.section-title{
  font-size: 21px;
  font-weight: 900;
  margin: 6px 0 10px;
}
.hl{
  background: rgba(255,109,0,0.30);
  padding: 0 4px;
  border-radius: 7px;
  font-weight: 900;
}
.small-note{
  color: rgba(23,23,23,0.72);
  font-size: 13px;
  font-weight: 700;
}

.emoji, .emoji *{
  font-family: "Apple Color Emoji", "Segoe UI Emoji", "Noto Color Emoji", "Pretendard", system-ui, sans-serif !important;
}
</style>
"""
st.markdown(CSS, unsafe_allow_html=True)


# =========================================================
# Secrets / Key loading
# =========================================================
def get_secret(name: str) -> Optional[str]:
    try:
        v = st.secrets.get(name)
        if v:
            return str(v)
    except Exception:
        pass
    v = os.environ.get(name)
    return str(v) if v else None


DEFAULT_OPENAI_MODEL = get_secret("DEFAULT_OPENAI_MODEL") or "gpt-5-mini"

AI_SYSTEM = """ë„ˆëŠ” Burning Beaver(Beaver Rocks) í–‰ì‚¬ì˜ ê¸°íš/ìš´ì˜ì§„ì„ ë•ëŠ” ë°ì´í„° ë¶„ì„ ë³´ì¡°ìë‹¤.

ë°˜ë“œì‹œ ì§€í‚¬ ê·œì¹™:
- ì¶œë ¥ì€ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•œë‹¤.
- ëª¨ë“  ë¬¸ì¥ì€ ì¡´ëŒ“ë§(í•©ë‹ˆë‹¤/ë©ë‹ˆë‹¤/ì„¸ìš”)ë¡œ ëë‚˜ì•¼ í•œë‹¤. ë°˜ë§ ê¸ˆì§€.
- ì œê³µëœ ë°ì´í„°(ì—°ë„ë³„ í‚¤ì›Œë“œ/ì–¸ê¸‰ ê¸€ ìˆ˜/ì˜ˆì‹œ ì¼ë¶€/ê³µì‹ ë¦¬ìŠ¤íŠ¸ ì •ë³´/ì›ë¬¸ ìŠ¤ë‹ˆí«)ë§Œ ê·¼ê±°ë¡œ ì“´ë‹¤.
- ê³¼ì¥/ë‹¨ì • ê¸ˆì§€. ì¶”ì¸¡ì´ë©´ 'ê°€ì„¤'ì´ë¼ê³  ëª…ì‹œí•œë‹¤.
- AI ìš”ì•½/2026 ë°©í–¥ì„± ë²„íŠ¼ ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œ ì¤„(1ë¬¸ì¥)ë¡œ ì‘ì„±í•˜ê³ , ë‹¤ë¥¸ ì„¹ì…˜ ë‚´ìš©ì„ ë§ë¶™ì´ì§€ ì•ŠëŠ”ë‹¤.
- ì±—ë´‡ ë‹µë³€ì€ ì‰¬ìš´ í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ë˜, ê°€ëŠ¥í•œ 3~7ì¤„ ë‚´ë¡œ ì •ë¦¬í•œë‹¤.
"""

AI_ACCESS_CODE = get_secret("AI_ACCESS_CODE")  # optional gate


# =========================================================
# Sidebar
# =========================================================
with st.sidebar:
    st.markdown("## âš™ï¸ ì„¤ì •")

    st.markdown("### ğŸ«§ íƒœê·¸ ë²„ë¸”")
    bubble_top_n = st.slider("Top N", min_value=3, max_value=8, value=6, step=1)
    bubble_show_count = st.checkbox("ë¼ë²¨ì— ì–¸ê¸‰ëŸ‰ í‘œì‹œ", value=True)

    st.divider()

    st.markdown("### ğŸ§© ìš´ì˜ìš”ì†Œ")
    elem_top_n = st.slider("ì—°ë„ë³„ Top N", 5, 10, 10, 1)
    elem_type = st.selectbox(
        "ë¶„ë¥˜(type)",
        ["ì „ì²´", "ì—°ì‚¬/ì¸í”Œë£¨ì–¸ì„œ", "êµ¿ì¦ˆ/ë¦¬ì›Œë“œ", "ì¥ì†Œ/ê³µê°„", "íŒŒíŠ¸ë„ˆì‰½", "ì´ë²¤íŠ¸", "ìš´ì˜ì¸ë ¥", "ê²Œì„/IP", "ë„¤íŠ¸ì›Œí‚¹"]
    )
    elem_q = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", value="").strip()

    st.divider()

    st.markdown("### ğŸ® ì „ì‹œ ê²Œì„")
    game_top_n = st.slider("ì—°ë„ë³„ Top N(íŠ¸ë¦¬ë§µ)", min_value=5, max_value=10, value=10, step=1)

    st.divider()

    st.markdown("### <span class=\"emoji\">ğŸ¤–</span> AI (ìš”ì•½/ì¶”ì²œ/ì±—ë´‡)", unsafe_allow_html=True)
    ai_enabled = st.toggle("AI ê¸°ëŠ¥ ì¼œê¸°", value=False)

    # âœ… ìš”ì²­: ì‚¬ì´ë“œë°”ì—ì„œ í‚¤ ì…ë ¥(ê³µìœ  í‰ê°€ìš©)
    if "openai_key_input" not in st.session_state:
        st.session_state.openai_key_input = ""

    openai_key_input = st.text_input(
        "OpenAI API Key (ì„ íƒ)",
        type="password",
        value=st.session_state.openai_key_input,
        help="ê³µìœ ìš©ìœ¼ë¡œ secrets/envì— í‚¤ë¥¼ ë„£ì§€ ì•Šì„ ë•Œë§Œ ì‚¬ìš©í•˜ì„¸ìš”. (ì½”ë“œ/ê¹ƒí—ˆë¸Œì— ì ˆëŒ€ í•˜ë“œì½”ë”© ê¸ˆì§€)"
    )
    st.session_state.openai_key_input = openai_key_input

    ai_model = st.text_input("ëª¨ë¸", value=DEFAULT_OPENAI_MODEL)
    # âœ… ê³ ì • íŒŒë¼ë¯¸í„°(ê³µìœ /í‰ê°€ìš©): ì‚¬ìš©ìê°€ ì¡°ì • ë¶ˆê°€
    ai_char_limit = 500
    ai_temp = 0.4

    # Optional access gate for public sharing
    ai_unlocked = True
    if AI_ACCESS_CODE:
        st.caption("ğŸ”’ AI ì ê¸ˆ(ê³µìœ ìš©): ì ‘ê·¼ ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        entered = st.text_input("AI ì ‘ê·¼ ì½”ë“œ", type="password")
        ai_unlocked = bool(entered) and entered == AI_ACCESS_CODE


def get_openai_api_key() -> Optional[str]:
    # ìš°ì„ ìˆœìœ„: ì‚¬ì´ë“œë°” ì…ë ¥ > secrets/env
    if st.session_state.get("openai_key_input"):
        return str(st.session_state["openai_key_input"]).strip()
    return get_secret("OPENAI_API_KEY")


# =========================================================
# Loaders
# =========================================================
@st.cache_data(show_spinner=False)
def load_bubble(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["year"] = df["year"].astype(int)
    df["tag"] = df["tag"].astype(str)
    df["MentionedPosts"] = pd.to_numeric(df["MentionedPosts"], errors="coerce").fillna(0).astype(int)
    return df

@st.cache_data(show_spinner=False)
def load_elements(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)

    if "element_display" in df.columns:
        df["keyword"] = df["element_display"].astype(str)
    elif "keyword" in df.columns:
        df["keyword"] = df["keyword"].astype(str)
    else:
        df["keyword"] = df["element"].astype(str)

    if "examples_json" not in df.columns:
        df["examples_json"] = "[]"
    if "type" not in df.columns:
        df["type"] = "unknown"

    df["year"] = df["year"].astype(int)
    df["MentionedPosts"] = pd.to_numeric(df["MentionedPosts"], errors="coerce").fillna(0).astype(int)
    return df

@st.cache_data(show_spinner=False)
def load_games(path: str) -> pd.DataFrame:
    df = pd.read_csv(path)
    df["year"] = df["year"].astype(int)
    df["MentionedPosts"] = pd.to_numeric(df["MentionedPosts"], errors="coerce").fillna(0).astype(int)
    df["game"] = df["game"].astype(str)
    return df


# =========================================================
# Header
# =========================================================
st.markdown(
    f"""
    <div class="hero">
      <h1>ğŸ¦«ğŸ”¥ Burning Beaver (Beaver Rocks) â€” í›„ê¸° í†µí•© ëŒ€ì‹œë³´ë“œ</h1>
      <div class="sub">ë„¤ì´ë²„ ë¸”ë¡œê·¸ í›„ê¸° ê¸°ë°˜ #ì´ë¯¸ì§€ í‚¤ì›Œë“œ #ìš´ì˜ìš”ì†Œ #ì „ì‹œ ê²Œì„</div>
      <div class="chips">
        <span class="chip">ğŸ—“ï¸ 2022â€“2025</span>
        <span class="chip">ğŸŒ <a href="{BEAVERROCKS_URL}" target="_blank" rel="noreferrer">Beaver Rocks í™ˆí˜ì´ì§€ ë°”ë¡œê°€ê¸°</a></span>
      </div>
    </div>
    """,
    unsafe_allow_html=True
)


# =========================================================
# Helpers
# =========================================================
TYPE_EMOJI = {
    "ì—°ì‚¬/ì¸í”Œë£¨ì–¸ì„œ": "ğŸ¤",
    "êµ¿ì¦ˆ/ë¦¬ì›Œë“œ": "ğŸ",
    "ì¥ì†Œ/ê³µê°„": "ğŸ—ºï¸",
    "íŒŒíŠ¸ë„ˆì‰½": "ğŸ¤",
    "ì´ë²¤íŠ¸": "ğŸª",
    "ìš´ì˜ì¸ë ¥": "ğŸ”§",
    "ê²Œì„/IP": "ğŸ®",
    "ë„¤íŠ¸ì›Œí‚¹": "ğŸŒ",
}



@st.cache_data(show_spinner=False)
def load_fulltext(path: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.DataFrame(columns=["title","link","full_text","year"])
    if "year" in df.columns:
        df["year"] = pd.to_numeric(df["year"], errors="coerce").fillna(0).astype(int)
    for c in ["title", "link", "full_text"]:
        if c in df.columns:
            df[c] = df[c].astype(str)
    return df

@st.cache_data(show_spinner=False)
def load_official_games(path: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(path)
    except Exception:
        return pd.DataFrame(columns=["No","Name","Year"])
    if "Year" in df.columns:
        df["Year"] = pd.to_numeric(df["Year"], errors="coerce").fillna(0).astype(int)
    if "Name" in df.columns:
        df["Name"] = df["Name"].astype(str)
    return df

@st.cache_data(show_spinner=False)
def load_official_elements(path: str) -> pd.DataFrame:
    try:
        return pd.read_csv(path)
    except Exception:
        return pd.DataFrame()


def em(t: str) -> str:
    return TYPE_EMOJI.get(str(t).strip(), "âœ¨")

def parse_examples(examples_json: str) -> List[Dict[str, str]]:
    try:
        arr = json.loads(examples_json) if isinstance(examples_json, str) else []
    except Exception:
        arr = []
    cleaned = []
    for ex in arr[:5]:
        cleaned.append({
            "context": (ex.get("context") or "").strip(),
            "title": (ex.get("title") or "").strip(),
            "link": (ex.get("link") or "").strip(),
        })
    return cleaned

def highlight(text: str) -> str:
    safe = (text or "").replace("\n", " ").strip()
    safe = re.sub(r"\s+", " ", safe)
    safe = safe.replace("&", "&amp;").replace("<", "&lt;").replace(">", "&gt;")
    safe = safe.replace("[[", "<span class='hl'>").replace("]]", "</span>")
    return safe

def hex_to_rgb(h: str) -> Tuple[int, int, int]:
    h = h.lstrip("#")
    return tuple(int(h[i:i+2], 16) for i in (0, 2, 4))

def rgb_to_hex(rgb: Tuple[int, int, int]) -> str:
    return "#{:02X}{:02X}{:02X}".format(*rgb)

def lerp(a: int, b: int, t: float) -> int:
    return int(a + (b - a) * t)

def color_by_value(val: int, vmin: int, vmax: int) -> str:
    start = hex_to_rgb("#FFCC80")  # light orange
    mid   = hex_to_rgb("#FF6D00")  # orange
    end   = hex_to_rgb("#C62828")  # deep red

    if vmax <= vmin:
        t = 1.0
    else:
        t = (val - vmin) / (vmax - vmin)
        t = max(0.0, min(1.0, t))

    if t < 0.55:
        tt = t / 0.55
        rgb = (lerp(start[0], mid[0], tt), lerp(start[1], mid[1], tt), lerp(start[2], mid[2], tt))
    else:
        tt = (t - 0.55) / 0.45
        rgb = (lerp(mid[0], end[0], tt), lerp(mid[1], end[1], tt), lerp(mid[2], end[2], tt))
    return rgb_to_hex(rgb)

def wrap_label(s: str, width: int = 9) -> str:
    s = s.strip()
    if len(s) <= width:
        return s
    if " " in s:
        parts, cur = [], ""
        for w in s.split():
            if len(cur) + len(w) + 1 <= width:
                cur = (cur + " " + w).strip()
            else:
                parts.append(cur)
                cur = w
        if cur:
            parts.append(cur)
        parts = parts[:2]
        if len(parts) == 2:
            parts[-1] += "â€¦"
        return "<br>".join(parts)
    return s[:width] + "<br>" + s[width:width*2] + ("â€¦" if len(s) > width*2 else "")
def normalize_text(s: str) -> str:
    s = (s or "").lower()
    s = re.sub(r"\s+", " ", s).strip()
    return s

def split_light_sentences(text: str, max_sent: int = 10) -> List[str]:
    lines = [ln.strip() for ln in (text or "").splitlines() if ln.strip()]
    if len(lines) > 13:
        lines = lines[13:]
    joined = " ".join(lines)
    parts = re.split(r"(?<=[\.\!\?\ã€‚\ï¼\ï¼Ÿâ€¦])\s+|(?<=[ë‹¤ìš”ì£ ì„í•¨])\s+", joined)
    parts = [p.strip() for p in parts if p and len(p.strip()) >= 12]
    return parts[:max_sent]

def retrieve_fulltext_snippets(df_full: pd.DataFrame, query: str, year: Optional[int], max_posts: int = 2) -> List[str]:
    q = (query or "").strip()
    if not q or df_full is None or df_full.empty or "full_text" not in df_full.columns:
        return []
    tokens = [t for t in re.split(r"[^\wê°€-í£]+", q) if len(t) >= 2][:6]
    if not tokens:
        return []
    pat = "(" + "|".join([re.escape(t) for t in tokens]) + ")"
    sub = df_full
    if year is not None and "year" in sub.columns:
        sub = sub[sub["year"] == int(year)]
    cand = sub[sub["full_text"].astype(str).str.contains(pat, case=False, na=False, regex=True)].head(18)
    snippets = []
    for _, r in cand.iterrows():
        sents = split_light_sentences(str(r.get("full_text", "")), max_sent=12)
        chosen = [ss for ss in sents if re.search(pat, ss, flags=re.IGNORECASE)][:2]
        if chosen:
            snippets.append(" / ".join(chosen)[:420])
        if len(snippets) >= max_posts:
            break
    return snippets

def detect_official_game_mentions(df_off: pd.DataFrame, query: str, year: Optional[int]) -> List[str]:
    if df_off is None or df_off.empty or "Name" not in df_off.columns:
        return []
    qn = normalize_text(query)
    if not qn:
        return []
    sub = df_off
    if year is not None and "Year" in sub.columns:
        sub = sub[sub["Year"] == int(year)]
    hits = []
    for name in sub["Name"].dropna().astype(str).tolist():
        n = normalize_text(name)
        if len(n) >= 3 and n in qn:
            hits.append(name)
        if len(hits) >= 8:
            break
    return hits


def detect_official_element_mentions(df_off_el: pd.DataFrame, query: str, year: Optional[int]) -> List[str]:
    if df_off_el is None or df_off_el.empty or "element" not in df_off_el.columns:
        return []
    qn = normalize_text(query)
    if not qn:
        return []
    sub = df_off_el
    if year is not None and "Year" in sub.columns:
        sub = sub[sub["Year"] == int(year)]
    hits = []
    for el in sub["element"].dropna().astype(str).tolist():
        n = normalize_text(el)
        if len(n) >= 2 and n in qn:
            hits.append(el)
        if len(hits) >= 10:
            break
    return hits


def bubble_plotly(year_df: pd.DataFrame, show_count: bool, height: int = 330):
    """
    âœ… ìš”ì²­ ë°˜ì˜:
    - ë²„ë¸” ë¼ë²¨ ë°°ê²½ ë„¤ëª¨ ì œê±° (bgcolor/border ì‚­ì œ)
    - ê¸€ìëŠ” ê²€ì€ìƒ‰
    - ê¸€ì í¬ê¸° ì‘ê²Œ
    """
    year_df = year_df.sort_values(["MentionedPosts", "tag"], ascending=[False, True]).copy()
    year_df = year_df[year_df["MentionedPosts"] > 0].reset_index(drop=True)

    data = [{"id": str(t), "datum": int(v)} for t, v in zip(year_df["tag"], year_df["MentionedPosts"])]
    if not data:
        return go.Figure(), year_df

    circles = circlify.circlify(
        data,
        show_enclosure=False,
        target_enclosure=circlify.Circle(x=0, y=0, r=1),
    )

    leaves = [c for c in circles if isinstance(getattr(c, "ex", None), dict) and "id" in c.ex and "datum" in c.ex]
    leaves = sorted(leaves, key=lambda c: c.ex["datum"], reverse=True)

    values = [c.ex["datum"] for c in leaves]
    vmin, vmax = min(values), max(values)

    fig = go.Figure()
    for c in leaves:
        x, y, r = c.x, c.y, c.r
        tag = str(c.ex["id"])
        cnt = int(c.ex["datum"])

        fill = color_by_value(cnt, vmin, vmax)

        fig.add_shape(
            type="circle",
            xref="x", yref="y",
            x0=x - r, y0=y - r, x1=x + r, y1=y + r,
            line=dict(color="rgba(255,255,255,0.60)", width=2),
            fillcolor=fill,
            opacity=0.97,
            layer="below",
        )

        base = r * 34 + 5
        penalty = max(0, len(tag) - 7)
        font_size = int(base - penalty * 1.0)
        font_size = max(8, min(14, font_size))

        safe_tag = html.escape(tag)
        safe_tag = wrap_label(safe_tag, width=9)

        show_cnt_here = bool(show_count and r >= 0.16)
        label = f"{safe_tag}<br>({cnt})" if show_cnt_here else f"{safe_tag}"

        fig.add_annotation(
            x=x, y=y,
            text=f"<b>{label}</b>",
            showarrow=False,
            font=dict(size=font_size, color="#111111", family="Pretendard, sans-serif"),
            align="center",
        )

    fig.update_xaxes(visible=False, range=[-1.05, 1.05])
    fig.update_yaxes(visible=False, range=[-1.05, 1.05], scaleanchor="x", scaleratio=1)
    fig.update_layout(
        margin=dict(l=0, r=0, t=0, b=0),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        height=height,
    )
    return fig, year_df


# =========================================================
# OpenAI (HTTP) - Responses API
# =========================================================
def extract_output_text(resp_json: Dict[str, Any]) -> str:
    """Responses API ì‘ë‹µì—ì„œ ì‚¬ëŒì´ ì½ì„ í…ìŠ¤íŠ¸ë§Œ ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œ."""
    if not isinstance(resp_json, dict):
        return ""

    ot = resp_json.get("output_text")
    if isinstance(ot, str) and ot.strip():
        return ot.strip()

    out = resp_json.get("output")
    if isinstance(out, list):
        parts = []
        for item in out:
            if not isinstance(item, dict):
                continue

            if item.get("type") == "message":
                content = item.get("content") or []
                if isinstance(content, list):
                    for c in content:
                        if not isinstance(c, dict):
                            continue
                        if c.get("type") in ("output_text", "text"):
                            txt = c.get("text")
                            if isinstance(txt, str) and txt.strip():
                                parts.append(txt.strip())

            if item.get("type") in ("output_text", "text"):
                txt = item.get("text")
                if isinstance(txt, str) and txt.strip():
                    parts.append(txt.strip())

        if parts:
            return "\n".join(parts).strip()

    return ""


def supports_temperature(model: str) -> bool:
    m = str(model).strip()
    # ì¼ë¶€ ëª¨ë¸ì€ temperature ì „ë‹¬ ì‹œ 400ì´ ë‚  ìˆ˜ ìˆì–´ ì•ˆì „í•˜ê²Œ ì œí•œ
    return m.startswith("gpt-5.2") or m.startswith("gpt-4")

def supports_reasoning_param(model: str) -> bool:
    m = str(model).strip()
    return m.startswith("gpt-5") or m.startswith("o")

def call_openai_responses(
    api_key: str,
    model: str,
    system: str,
    user: str,
    max_output_tokens: int = 1800,
    temperature: Optional[float] = None,
    timeout: int = 90,
    reasoning_effort: str = "low",
    retries: int = 2,
) -> Tuple[str, Dict[str, Any]]:
    """
    - í…ìŠ¤íŠ¸ê°€ ë¹„ê±°ë‚˜(incomplete) JSONë§Œ ë³´ì´ëŠ” ë¬¸ì œ ë°©ì§€:
      max_output_tokensë¥¼ ë„‰ë„‰íˆ ì£¼ê³ , í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ìë™ ì¬ì‹œë„.
    - temperature ë¯¸ì§€ì› ëª¨ë¸ì€ ìë™ìœ¼ë¡œ ì œê±°í•˜ê³  ì¬ì‹œë„.
    """
    url = "https://api.openai.com/v1/responses"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }

    def _post(use_temp: bool, mot: int, use_reasoning: bool) -> Tuple[str, Dict[str, Any], int, str]:
        payload: Dict[str, Any] = {
            "model": model,
            "input": [
                {"role": "system", "content": system},
                {"role": "user", "content": user},
            ],
            "max_output_tokens": int(mot),
            "text": {"format": {"type": "text"}},
        }

        if use_reasoning and supports_reasoning_param(model):
            payload["reasoning"] = {"effort": reasoning_effort}

        if use_temp and (temperature is not None) and supports_temperature(model):
            payload["temperature"] = float(temperature)

        r = requests.post(url, headers=headers, json=payload, timeout=timeout)

        try:
            parsed = r.json() if r.content else {}
        except Exception:
            parsed = {}

        data: Dict[str, Any] = parsed if isinstance(parsed, dict) else {}

        err_obj = data.get("error")
        msg = err_obj.get("message") if isinstance(err_obj, dict) else None
        err_text = msg or (r.text or "")

        text = extract_output_text(data)
        return text, data, r.status_code, err_text

    mot = int(max_output_tokens)
    use_reasoning = True

    text, data, status, err = _post(True, mot, use_reasoning)

    # temperature ë¯¸ì§€ì› ìë™ ì¬ì‹œë„
    if status >= 400 and "Unsupported parameter" in str(err) and "temperature" in str(err):
        text, data, status, err = _post(False, mot, use_reasoning)

    if status >= 400:
        raise RuntimeError(f"OpenAI API error ({status}): {err}")

    for _ in range(int(retries)):
        if text and text.strip():
            break

        resp_status = str(data.get("status") or "").lower()
        inc = data.get("incomplete_details") or {}
        reason = (inc.get("reason") if isinstance(inc, dict) else "") or ""

        if resp_status == "incomplete" and "max_output_tokens" in str(reason):
            mot = int(mot * 2.0)
            text, data, status, err = _post(False, mot, use_reasoning)
            continue

        if use_reasoning:
            use_reasoning = False
            text, data, status, err = _post(False, mot, use_reasoning)
            continue

        break

    if not text or not text.strip():
        resp_status = data.get("status")
        inc = data.get("incomplete_details")
        return f"AI ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. (status={resp_status}, incomplete_details={inc})", data

    return text.strip(), data


def ai_available() -> bool:
    return bool(ai_enabled and ai_unlocked and get_openai_api_key())


def ai_guardrail_banner():
    if not ai_enabled:
        st.info("AI ê¸°ëŠ¥ì€ ì‚¬ì´ë“œë°”ì—ì„œ ì¼¤ ìˆ˜ ìˆì–´ìš”. (ê¸°ë³¸ OFF)")
        return
    if AI_ACCESS_CODE and not ai_unlocked:
        st.warning("AI ì ‘ê·¼ ì½”ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    if not get_openai_api_key():
        st.warning("OpenAI API Keyê°€ ì—†ìŠµë‹ˆë‹¤. (ì‚¬ì´ë“œë°”ì— ì…ë ¥í•˜ê±°ë‚˜ secrets/envì— ì„¤ì •)")
        return


def rate_limit_ok(max_calls: int = 30) -> bool:
    if "ai_calls" not in st.session_state:
        st.session_state.ai_calls = 0
    return st.session_state.ai_calls < max_calls


def bump_calls():
    st.session_state.ai_calls = int(st.session_state.get("ai_calls", 0)) + 1


def build_context_pack(
    df_b: pd.DataFrame,
    df_e: pd.DataFrame,
    df_g: pd.DataFrame,
    bubble_n: int,
    elem_n: int,
    game_n: int,
    elem_type_filter: str,
    elem_q_filter: str,
    df_off_games: Optional[pd.DataFrame] = None,
    df_off_elements: Optional[pd.DataFrame] = None,
) -> Dict[str, Any]:
    years = [2022, 2023, 2024, 2025]

    tags = {}
    for y in years:
        d = df_b[df_b["year"] == y].sort_values(["MentionedPosts", "tag"], ascending=[False, True]).head(bubble_n)
        tags[str(y)] = [{"tag": r["tag"], "posts": int(r["MentionedPosts"])} for _, r in d.iterrows()]

    ebase = df_e.copy()
    if elem_type_filter != "ì „ì²´":
        ebase = ebase[ebase["type"] == elem_type_filter]
    if elem_q_filter:
        ebase = ebase[ebase["keyword"].str.contains(elem_q_filter, case=False, na=False)]

    elements = {}
    for y in years:
        d = ebase[ebase["year"] == y].sort_values("MentionedPosts", ascending=False).head(elem_n).copy()
        rows = []
        for _, r in d.iterrows():
            ex = parse_examples(r.get("examples_json", "[]"))
            rows.append({
                "type": str(r.get("type", "")),
                "keyword": str(r.get("keyword", "")),
                "posts": int(r.get("MentionedPosts", 0)),
                "examples": [x.get("context", "")[:200] for x in ex[:2] if x.get("context")],
            })
        elements[str(y)] = rows

    games = {}
    for y in years:
        d = df_g[df_g["year"] == y].sort_values(["MentionedPosts", "game"], ascending=[False, True]).head(game_n)
        games[str(y)] = [{"game": r["game"], "posts": int(r["MentionedPosts"])} for _, r in d.iterrows()]

    official_meta: Dict[str, Any] = {}

    if df_off_games is not None and not df_off_games.empty and "Year" in df_off_games.columns:
        for y in years:
            official_meta.setdefault(str(y), {})
            official_meta[str(y)]["official_games_cnt"] = int((df_off_games["Year"] == y).sum())

    if df_off_elements is not None and not df_off_elements.empty:
        # expected cols: Year, element, type
        if "Year" in df_off_elements.columns:
            for y in years:
                official_meta.setdefault(str(y), {})
                official_meta[str(y)]["official_elements_cnt"] = int((df_off_elements["Year"] == y).sum())
                if "type" in df_off_elements.columns:
                    vc = df_off_elements[df_off_elements["Year"] == y]["type"].astype(str).value_counts()
                    official_meta[str(y)]["official_elements_by_type"] = vc.to_dict()
        official_meta["official_elements_rows"] = int(len(df_off_elements))

    return {"years": years, "tags": tags, "elements": elements, "games": games, "official_meta": official_meta}


def enforce_char_limit(text: str, limit: int) -> str:
    t = (text or "").strip()
    if len(t) <= limit:
        return t
    return t[:max(0, limit-1)] + "â€¦"




def pick_one_liner(raw_text: str, mode: str) -> str:
    """
    mode:
      - "summary": '2022â†’2025 ë³€ì²œì‚¬:' í•œ ë¬¸ì¥ë§Œ
      - "plan":    '2026 ì œì•ˆ:' í•œ ë¬¸ì¥ë§Œ
    ëª¨ë¸ì´ ì§€ì‹œë¥¼ ì–´ê¸°ê³  ë‹¤ë¥¸ ì„¹ì…˜ì„ ë§ë¶™ì¼ ë•Œë¥¼ ëŒ€ë¹„í•´ ë°©ì–´ì ìœ¼ë¡œ ì˜ë¼ëƒ…ë‹ˆë‹¤.
    """
    t = (raw_text or "").strip()

    # 1) ìš°ì„  prefix ê¸°ë°˜ìœ¼ë¡œ ì¶”ì¶œ
    if mode == "summary":
        pref = "2022â†’2025 ë³€ì²œì‚¬:"
        # ë‹¤ì–‘í•œ ê³µë°±/í™”ì‚´í‘œ ë³€í˜• í—ˆìš©
        m = re.search(r"(2022\s*â†’\s*2025\s*ë³€ì²œì‚¬\s*:\s*.+)", t)
        if m:
            t = m.group(1).strip()
    elif mode == "plan":
        pref = "2026 ì œì•ˆ:"
        m = re.search(r"(2026\s*ì œì•ˆ\s*:\s*.+)", t)
        if m:
            t = m.group(1).strip()
    else:
        pref = ""

    # 2) ë‹¤ë¥¸ ì„¹ì…˜/ë©”íƒ€ ë¬¸êµ¬ê°€ ë’¤ì— ë¶™ëŠ” ê²½ìš° ì˜ë¼ë‚´ê¸°
    cut_markers = [
        "AI ìš”ì•½", "2026 ë°©í–¥ì„±", "AI ì±—ë´‡", "ë²„íŠ¼:", "ë²„íŠ¼ :", "incomplete", '{"id"', '"object":', "ë³¸ ìš”ì•½",
    ]
    # summaryì—ë§Œ ì ìš©(2026ì€ ìš”ì•½ì—ì„œ íŠ¹íˆ ë¬¸ì œ)
    if mode == "summary":
        cut_markers = ["2026 ì œì•ˆ", "2026 ë°©í–¥ì„±", "2026ë…„"] + cut_markers

    # ê°€ì¥ ë¨¼ì € ë“±ì¥í•˜ëŠ” marker ìœ„ì¹˜ì—ì„œ ì˜ë¼ëƒ„(ë‹¨, prefix ìì²´ëŠ” ë³´ì¡´)
    earliest = None
    for mk in cut_markers:
        pos = t.find(mk)
        if pos != -1:
            # prefixê°€ marker ì•ˆì— ìˆëŠ” ê±´ ì œì™¸
            if pref and pos <= t.find(pref) + len(pref):
                continue
            if earliest is None or pos < earliest:
                earliest = pos
    if earliest is not None and earliest > 0:
        t = t[:earliest].rstrip()

    # 3) ì²« ë¬¸ì¥ë§Œ ë‚¨ê¸°ê¸°(ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ ê¸°ì¤€)
    # í•œêµ­ì–´ ë¬¸ì¥ì€ ë³´í†µ '.'ë¡œ ëë‚˜ë¯€ë¡œ '.' ê¸°ì¤€ ìš°ì„ , ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘ .
    # ë‹¤ë§Œ "2022â†’2025 ë³€ì²œì‚¬:" ëŠ” í•œ ë¬¸ì¥ë§Œ ìš”êµ¬í•˜ë¯€ë¡œ ì²« '.'ê¹Œì§€ ìœ ì§€
    sentence_end = None
    for p in [".", "!", "?"]:
        idx = t.find(p)
        if idx != -1:
            sentence_end = idx
            break
    if sentence_end is not None:
        t = t[:sentence_end+1].strip()

    # 4) ì¤„ë°”ê¿ˆ/ì—¬ë°± ì •ë¦¬
    t = t.replace("\n", " ").strip()
    t = re.sub(r"\s+", " ", t).strip()

    # 5) ì¡´ëŒ“ë§ ì¢…ê²° ë°©ì–´(ëì´ ë„ˆë¬´ ì˜ë¦¬ë©´ 'ì…ë‹ˆë‹¤.' ë¶™ì„)
    if t and not re.search(r"(ìŠµë‹ˆë‹¤\.?$|ì„¸ìš”\.?$|í•´ìš”\.?$|ë¼ìš”\.?$|ì…ë‹ˆë‹¤\.?$|í•©ë‹ˆë‹¤\.?$|ë©ë‹ˆë‹¤\.?$)", t):
        t = t.rstrip(" ,;:")
        if t.endswith("."):
            # ì´ë¯¸ ë¬¸ì¥ë¶€í˜¸ê°€ ìˆìœ¼ë©´ ë‹¨ìˆœíˆ ì¡´ëŒ“ë§ ë³´ì •ë§Œ ë¶™ì…ë‹ˆë‹¤.
            t = t[:-1].rstrip() + "ì…ë‹ˆë‹¤."
        else:
            t += "ì…ë‹ˆë‹¤."
    return t
def ai_panel(title: str, user_prompt: str, context_obj: Dict[str, Any], key_prefix: str):
    st.markdown(f"### <span class=\"emoji\">ğŸ¤–</span> {title}", unsafe_allow_html=True)
    ai_guardrail_banner()
    if not ai_available():
        return
    if not rate_limit_ok():
        st.warning("AI í˜¸ì¶œ í•œë„(ì„¸ì…˜)ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. (ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì´ˆê¸°í™”)")
        return

    colA, colB, colC = st.columns([1, 1, 2])
    with colA:
        btn_summary = st.button("AI ìš”ì•½", key=f"{key_prefix}_sum")
    with colB:
        btn_plan = st.button("2026 ë°©í–¥ì„±", key=f"{key_prefix}_plan")
    with colC:
        with st.expander("AIì— ì „ë‹¬ë˜ëŠ” ìš”ì•½ ë°ì´í„°(ê²€ì¦ìš©)", expanded=False):
            st.json(context_obj)

    if not (btn_summary or btn_plan):
        st.caption("ë²„íŠ¼ì„ ëˆŒë €ì„ ë•Œë§Œ í˜¸ì¶œí•©ë‹ˆë‹¤. (ê¸°ë³¸ OFF / ë¹„ìš© ë³´í˜¸)")
        return

    bump_calls()

    if btn_summary:
        user = user_prompt + f"\n\nì¶œë ¥: '2022â†’2025 ë³€ì²œì‚¬: ...' í˜•ì‹ì˜ í•œ ì¤„(1ë¬¸ì¥)ë§Œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¹ì…˜(ì˜ˆ: 2026 ì œì•ˆ/ë°©í–¥ì„±) ë‚´ìš©, ë©”íƒ€ ì„¤ëª…, ì£¼ì˜ë¬¸, ê°€ì„¤ ë¬¸êµ¬ë¥¼ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”. ì´ {ai_char_limit}ì ì´ë‚´."
        kicker = "AI ìš”ì•½"
    else:
        user = user_prompt + f"\n\nì¶œë ¥: '2026 ì œì•ˆ: ...' í˜•ì‹ì˜ í•œ ì¤„(1ë¬¸ì¥)ë§Œ ì‘ì„±í•˜ì„¸ìš”. '2022â†’2025 ë³€ì²œì‚¬:' ë¬¸êµ¬ë¥¼ ì¶œë ¥í•˜ê±°ë‚˜, AI ìš”ì•½ ë²„íŠ¼ ê´€ë ¨ ë¬¸ì¥ì„ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”. (2022â†’2025 íë¦„ì€ ë¬¸ì¥ ì•ˆì—ì„œ ê·¼ê±°ë¡œ ë°˜ì˜) ì´ {ai_char_limit}ì ì´ë‚´."
        kicker = "2026 ë°©í–¥ì„±"

    with st.spinner("AI ìƒì„± ì¤‘..."):
        try:
            key = get_openai_api_key()
            text, _meta = call_openai_responses(
                api_key=key,
                model=ai_model,
                system=AI_SYSTEM,
                user=user,
                max_output_tokens=1800,
                temperature=ai_temp,
                timeout=90,
                reasoning_effort="low",
                retries=2,
            )
            raw_text = (text or "").strip()
            text = pick_one_liner(raw_text, mode="summary" if btn_summary else "plan")
            text = enforce_char_limit(text, ai_char_limit)

            st.markdown(
                f"""
                <div class="card">
                  <div class="kicker">{html.escape(kicker)}</div>
                  <div style="font-size:18px; line-height:1.75; white-space:pre-wrap;">{html.escape(text)}</div>
                </div>
                """,
                unsafe_allow_html=True
            )
        except Exception as e:
            st.error(str(e))

# =========================================================
# Load data once
# =========================================================
try:
    df_bubble_all = load_bubble(BUBBLE_CSV)
    df_elements_all = load_elements(ELEMENTS_CSV)
    df_games_all = load_games(GAMES_CSV)

    df_fulltext = load_fulltext(FULLTEXT_CSV)
    df_off_games = load_official_games(OFFICIAL_GAMES_CSV)
    df_off_elements = load_official_elements(OFFICIAL_ELEMENTS_CSV)
except Exception as e:
    st.error(f"CSV ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()


# =========================================================
# Tabs
# =========================================================
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ«§ í–‰ì‚¬ ì´ë¯¸ì§€ í‚¤ì›Œë“œ", "ğŸ§© ìš´ì˜ìš”ì†Œ", "ğŸ® ì „ì‹œ ê²Œì„", "ğŸ’¬ AI ì±—ë´‡"])


with tab1:
    st.markdown('<div class="section-title">ğŸ«§ ì—°ë„ë³„ â€œí–‰ì‚¬ ì´ë¯¸ì§€â€ í‚¤ì›Œë“œ</div>', unsafe_allow_html=True)

    years = sorted(df_bubble_all["year"].unique().tolist())
    years = [y for y in [2022, 2023, 2024, 2025] if y in years] or years
    years = years[:4]

    cols = st.columns(4)
    for col, y in zip(cols, years):
        with col:
            st.markdown(f"#### {y}")
            yd = df_bubble_all[df_bubble_all["year"] == int(y)].copy()
            yd = yd.sort_values(["MentionedPosts", "tag"], ascending=[False, True]).head(bubble_top_n).copy()
            if yd.empty:
                st.caption("ë°ì´í„° ì—†ìŒ")
                continue

            fig, _ = bubble_plotly(yd, bubble_show_count, height=320)
            st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    ctx = build_context_pack(
        df_b=df_bubble_all,
        df_e=df_elements_all,
        df_g=df_games_all,
        df_off_games=df_off_games,
        df_off_elements=df_off_elements,
        bubble_n=bubble_top_n,
        elem_n=min(6, elem_top_n),
        game_n=min(8, game_top_n),
        elem_type_filter=elem_type,
        elem_q_filter=elem_q,
    )
    prompt = "ë‹¤ìŒì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í›„ê¸° í…ìŠ¤íŠ¸ë§ˆì´ë‹ ê¸°ë°˜ ì—°ë„ë³„ ë°ì´í„° ìš”ì•½ì´ë‹¤.\n" \
             f"- ì„¹ì…˜: ì´ë¯¸ì§€ í‚¤ì›Œë“œ(íƒœê·¸)\n- ë°ì´í„°(JSON):\n{json.dumps({'years': ctx['years'], 'tags': ctx['tags'], 'official_meta': ctx.get('official_meta', {})}, ensure_ascii=False)}"
    ai_panel("ì´ë¯¸ì§€ í‚¤ì›Œë“œ ì¸ì‚¬ì´íŠ¸", prompt, {"years": ctx["years"], "tags": ctx["tags"]}, "ai_tags")


with tab2:
    st.markdown('<div class="section-title">ğŸ§© ì—°ë„ë³„ ìš´ì˜ìš”ì†Œ í‚¤ì›Œë“œ & ì–¸ê¸‰ ë§¥ë½</div>', unsafe_allow_html=True)

    base = df_elements_all.copy()
    if elem_type != "ì „ì²´":
        base = base[base["type"] == elem_type]
    if elem_q:
        base = base[base["keyword"].str.contains(elem_q, case=False, na=False)]

    years = sorted(df_elements_all["year"].unique().tolist())
    years = [y for y in [2022, 2023, 2024, 2025] if y in years] or years
    year_tabs = st.tabs([f"{y}ë…„" for y in years])

    for tab, y in zip(year_tabs, years):
        with tab:
            v = base[base["year"] == int(y)].copy()
            if v.empty:
                st.info("ì´ ì—°ë„ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue

            v = v.sort_values("MentionedPosts", ascending=False).head(elem_top_n).reset_index(drop=True)
            v["label"] = v.apply(lambda r: f"{em(r['type'])} {r['keyword']}", axis=1)

            chart_df = v.sort_values("MentionedPosts", ascending=True)
            fig = px.bar(chart_df, x="MentionedPosts", y="label", orientation="h")
            fig.update_traces(
                marker_color="#FF6D00",
                hovertemplate="<b>%{y}</b><br>ì–¸ê¸‰ ê¸€ ìˆ˜: %{x}<extra></extra>",
            )
            fig.update_layout(
                height=max(540, 46 * len(chart_df) + 160),
                margin=dict(l=10, r=10, t=10, b=10),
                xaxis_title="",
                yaxis_title="",
                yaxis=dict(tickfont=dict(size=21)),
                xaxis=dict(tickfont=dict(size=13)),
                font=dict(family="Pretendard, sans-serif", size=18),
            )
            st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

            for _, r in v.iterrows():
                header = f"{em(r['type'])} {r['keyword']}  Â·  ğŸ§¾ {int(r['MentionedPosts'])}"
                with st.expander(header, expanded=False):
                    examples = parse_examples(r.get("examples_json", "[]"))
                    if not examples:
                        st.info("ì˜ˆì‹œ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
                        continue

                    for j, ex in enumerate(examples, 1):
                        ctx_html = highlight(ex["context"])
                        title = ex["title"] if ex["title"] else "ì›ë¬¸"
                        link = ex["link"]

                        if link:
                            shown = title if len(title) <= 90 else title[:90] + "â€¦"
                            link_html = f"ğŸ”— <a href='{link}' target='_blank' rel='noreferrer'>{shown}</a>"
                        else:
                            link_html = "ğŸ”— (ë§í¬ ì—†ìŒ)"

                        st.markdown(
                            f"""
                            <div class="card">
                              <div class="kicker">{em(r['type'])} ì˜ˆì‹œ {j}</div>
                              <div style="font-size:18px; line-height:1.75;">{ctx_html}</div>
                              <div style="margin-top:8px; font-size:13px; color: rgba(23,23,23,0.75);">{link_html}</div>
                            </div>
                            """,
                            unsafe_allow_html=True
                        )

    ctx = build_context_pack(
        df_b=df_bubble_all,
        df_e=df_elements_all,
        df_g=df_games_all,
        df_off_games=df_off_games,
        df_off_elements=df_off_elements,
        bubble_n=min(6, bubble_top_n),
        elem_n=elem_top_n,
        game_n=min(8, game_top_n),
        elem_type_filter=elem_type,
        elem_q_filter=elem_q,
    )
    prompt = "ë‹¤ìŒì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í›„ê¸° í…ìŠ¤íŠ¸ë§ˆì´ë‹ ê¸°ë°˜ ì—°ë„ë³„ ë°ì´í„° ìš”ì•½ì´ë‹¤.\n" \
             f"- ì„¹ì…˜: ìš´ì˜ìš”ì†Œ(í‚¤ì›Œë“œ+ì¼ë¶€ ì˜ˆì‹œ ë¬¸ì¥)\n- í•„í„°: type={elem_type}, query='{elem_q or ''}'\n- ë°ì´í„°(JSON):\n{json.dumps({'years': ctx['years'], 'elements': ctx['elements'], 'official_meta': ctx.get('official_meta', {})}, ensure_ascii=False)}"
    ai_panel("ìš´ì˜ìš”ì†Œ ì¸ì‚¬ì´íŠ¸", prompt, {"years": ctx["years"], "elements": ctx["elements"]}, "ai_elements")


with tab3:
    st.markdown('<div class="section-title">ğŸ® ì—°ë„ë³„ ì „ì‹œ ê²Œì„ ì–¸ê¸‰ëŸ‰ TOP</div>', unsafe_allow_html=True)

    df_g = (
        df_games_all.sort_values(["year", "MentionedPosts", "game"], ascending=[True, False, True])
            .groupby("year", as_index=False)
            .head(game_top_n)
    )

    RANK_COLORS = [
        "#B00020", "#C21807", "#D32F2F", "#E53935", "#F4511E",
        "#FB5E00", "#FF6D00", "#FF7A1A", "#FF8F00", "#FFA000",
    ]

    def year_ranked(df_all: pd.DataFrame, year: int) -> pd.DataFrame:
        d = df_all[df_all["year"] == year].copy()
        if d.empty:
            return d
        d = d.sort_values(["MentionedPosts", "game"], ascending=[False, True]).reset_index(drop=True)
        d["rank"] = range(1, len(d) + 1)
        d["color"] = d["rank"].apply(lambda r: RANK_COLORS[r-1] if 1 <= r <= len(RANK_COLORS) else RANK_COLORS[-1])
        return d

    cols = st.columns(4)
    for i, year in enumerate([2022, 2023, 2024, 2025]):
        with cols[i]:
            st.markdown(f"### {year}")
            d = year_ranked(df_g, year)
            if d.empty:
                st.caption("ë°ì´í„° ì—†ìŒ")
                continue

            fig = go.Figure(go.Treemap(
                labels=d["game"].astype(str).tolist(),
                parents=[""] * len(d),
                values=d["MentionedPosts"].astype(int).tolist(),
                marker=dict(colors=d["color"].tolist(), line=dict(width=2, color="rgba(255,255,255,0.35)")),
                texttemplate="<b>%{label}</b><br>%{value}",
                textfont=dict(size=38, color="white"),
                hovertemplate="<b>%{label}</b><br>ì–¸ê¸‰ëŸ‰=%{value}<extra></extra>",
                branchvalues="total",
            ))
            fig.update_layout(
                height=560,
                margin=dict(l=4, r=4, t=6, b=4),
                paper_bgcolor="white",
            )
            st.plotly_chart(fig, use_container_width=True, config={"displayModeBar": False})

    ctx = build_context_pack(
        df_b=df_bubble_all,
        df_e=df_elements_all,
        df_g=df_games_all,
        df_off_games=df_off_games,
        df_off_elements=df_off_elements,
        bubble_n=min(6, bubble_top_n),
        elem_n=min(6, elem_top_n),
        game_n=game_top_n,
        elem_type_filter=elem_type,
        elem_q_filter=elem_q,
    )
    prompt = "ë‹¤ìŒì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ í›„ê¸° í…ìŠ¤íŠ¸ë§ˆì´ë‹ ê¸°ë°˜ ì—°ë„ë³„ ë°ì´í„° ìš”ì•½ì´ë‹¤.\n" \
             f"- ì„¹ì…˜: ì „ì‹œ ê²Œì„ Top\n- ë°ì´í„°(JSON):\n{json.dumps({'years': ctx['years'], 'games': ctx['games'], 'official_meta': ctx.get('official_meta', {})}, ensure_ascii=False)}"
    ai_panel("ì „ì‹œ ê²Œì„ ì¸ì‚¬ì´íŠ¸", prompt, {"years": ctx["years"], "games": ctx["games"]}, "ai_games")


with tab4:
    st.markdown('<div class="section-title">ğŸ’¬ AI ì±—ë´‡ â€” â€œAsk Beaver Rocksâ€</div>', unsafe_allow_html=True)
    st.markdown('<div class="small-note">ì§ˆë¬¸ì— ëŒ€í•´, í˜„ì¬ ëŒ€ì‹œë³´ë“œ ë°ì´í„°(íƒœê·¸/ìš´ì˜ìš”ì†Œ/ê²Œì„ Top + ìš´ì˜ìš”ì†Œ ì˜ˆì‹œ ì¼ë¶€)ë¥¼ ê·¼ê±°ë¡œ ë‹µí•©ë‹ˆë‹¤.</div>', unsafe_allow_html=True)

    ai_guardrail_banner()
    if not ai_available():
        st.stop()

    if not rate_limit_ok(max_calls=60):
        st.warning("AI í˜¸ì¶œ í•œë„(ì„¸ì…˜)ê°€ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. (ìƒˆë¡œê³ ì¹¨í•˜ë©´ ì´ˆê¸°í™”)")
        st.stop()

    if "chat" not in st.session_state:
        st.session_state.chat = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! 2022~2025 í›„ê¸° ê¸°ë°˜ìœ¼ë¡œ ìš´ì˜/ê¸°íš ì§ˆë¬¸ì„ ë„ì™€ë“œë¦´ê²Œìš”. ì˜ˆ: â€œ2026 ìš´ì˜ ìš°ì„ ìˆœìœ„ ë­ë¶€í„°?â€"}]

    c1, c2 = st.columns([2, 1])
    with c1:
        scope = st.selectbox("ê·¼ê±° ë²”ìœ„", ["ì „ì²´", "ì´ë¯¸ì§€ í‚¤ì›Œë“œ", "ìš´ì˜ìš”ì†Œ", "ì „ì‹œ ê²Œì„"])
    with c2:
        year_scope = st.selectbox("ì—°ë„", ["ì „ì²´", "2022", "2023", "2024", "2025"])

    ctx = build_context_pack(
        df_b=df_bubble_all,
        df_e=df_elements_all,
        df_g=df_games_all,
        df_off_games=df_off_games,
        df_off_elements=df_off_elements,
        bubble_n=bubble_top_n,
        elem_n=min(elem_top_n, 10),
        game_n=game_top_n,
        elem_type_filter=elem_type,
        elem_q_filter=elem_q,
    )

    def ctx_text_for(scope_: str, year_: str) -> str:
        years = [str(y) for y in ctx["years"]]
        if year_ != "ì „ì²´":
            years = [year_]
        parts = []
        # ê³µì‹ ë¦¬ìŠ¤íŠ¸(ê²Œì„/ìš´ì˜ìš”ì†Œ) ìš”ì•½
        omap = ctx.get("official_meta", {}) or {}
        if omap:
            parts.append("### ê³µì‹ ëª©ë¡(ì°¸ê³ )")
            for y in years:
                yy = str(y)
                om = omap.get(yy, {}) if isinstance(omap, dict) else {}
                if not isinstance(om, dict):
                    continue
                g = om.get("official_games_cnt")
                e = om.get("official_elements_cnt")
                t = om.get("official_elements_by_type") or {}
                line = f"- {yy}: ê³µì‹ê²Œì„ {g}ê°œ, ê³µì‹ìš´ì˜ìš”ì†Œ {e}ê°œ"
                if isinstance(t, dict) and t:
                    top4 = list(t.items())[:4]
                    line += " (" + ", ".join([f"{k}:{v}" for k, v in top4]) + ")"
                parts.append(line)
        if scope_ in ("ì „ì²´", "ì´ë¯¸ì§€ í‚¤ì›Œë“œ"):
            parts.append("### ì´ë¯¸ì§€ í‚¤ì›Œë“œ(íƒœê·¸) Top")
            for y in years:
                items = ctx["tags"].get(y, [])
                if items:
                    parts.append(f"- {y}: " + ", ".join([f"{it['tag']}({it['posts']})" for it in items]))
        if scope_ in ("ì „ì²´", "ìš´ì˜ìš”ì†Œ"):
            parts.append("### ìš´ì˜ìš”ì†Œ Top + ì˜ˆì‹œ ì¼ë¶€")
            for y in years:
                items = ctx["elements"].get(y, [])
                if items:
                    parts.append(f"- {y}:")
                    for it in items[:6]:
                        ex = it.get("examples") or []
                        ex_txt = (" / ".join(ex[:1])[:160]) if ex else ""
                        parts.append(f"  - {it['type']} | {it['keyword']} ({it['posts']})" + (f" | ì˜ˆ: {ex_txt}" if ex_txt else ""))
        if scope_ in ("ì „ì²´", "ì „ì‹œ ê²Œì„"):
            parts.append("### ì „ì‹œ ê²Œì„ Top")
            for y in years:
                items = ctx["games"].get(y, [])
                if items:
                    parts.append(f"- {y}: " + ", ".join([f"{it['game']}({it['posts']})" for it in items]))
        return "\n".join(parts)

    retrieval = ctx_text_for(scope, year_scope)

    for m in st.session_state.chat:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    user_msg = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 2026 ìš´ì˜ ìš°ì„ ìˆœìœ„ ë­ë¶€í„°?)")
    if user_msg:
        st.session_state.chat.append({"role": "user", "content": user_msg})
        with st.chat_message("user"):
            st.markdown(user_msg)

        bump_calls()

        y_int = None if year_scope == "ì „ì²´" else int(year_scope)
        snippets = retrieve_fulltext_snippets(df_fulltext, user_msg, y_int, max_posts=2)
        matched_games = detect_official_game_mentions(df_off_games, user_msg, y_int)
        matched_elems = detect_official_element_mentions(df_off_elements, user_msg, y_int)

        extra_ctx_lines = []
        if matched_games:
            extra_ctx_lines.append("ê³µì‹ ì „ì‹œ ê²Œì„(ì§ˆë¬¸ ë§¤ì¹­): " + ", ".join(matched_games))
        if matched_elems:
            extra_ctx_lines.append("ê³µì‹ ìš´ì˜ìš”ì†Œ(ì§ˆë¬¸ ë§¤ì¹­): " + ", ".join(matched_elems))
        if snippets:
            extra_ctx_lines.append("ì›ë¬¸ ìŠ¤ë‹ˆí«(ê·¼ê±° ì¼ë¶€):")
            extra_ctx_lines += [f"- {sn}" for sn in snippets]
        extra_ctx = "\n".join(extra_ctx_lines)

        system = AI_SYSTEM + "\nì¶”ê°€ ê·œì¹™: ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µí•˜ê³ , ëª¨ë“  ë¬¸ì¥ì€ ì¡´ëŒ“ë§ë¡œ ëë‚´ë©°, ê·¼ê±°ë¥¼ í¬í•¨í•˜ê³ , ê¸€ì ìˆ˜ ì œí•œì„ ì§€ì¼œë¼."
        user = (
            f"ì»¨í…ìŠ¤íŠ¸(ìš”ì•½):\n{retrieval}\n"
            + (f"\n{extra_ctx}\n" if extra_ctx else "\n")
            + f"ì§ˆë¬¸: {user_msg}\n\n"
            + f"ì¶œë ¥(ì´ {ai_char_limit}ì ì´ë‚´):\n"
            + "- ë‹µë³€\n- ê·¼ê±°(ë¶ˆë¦¿ 2~4ê°œ)\n- ë‹¤ìŒ ì•¡ì…˜(ë¶ˆë¦¿ 2~3ê°œ)"
        )

        with st.chat_message("assistant"):
            with st.spinner("AI ë‹µë³€ ìƒì„± ì¤‘..."):
                try:
                    key = get_openai_api_key()
                    text, meta = call_openai_responses(
                        api_key=key,
                        model=ai_model,
                        system=system,
                        user=user,
                        max_output_tokens=1800,
                        temperature=ai_temp,
                        timeout=90,
                    )
                    text = enforce_char_limit(text, ai_char_limit)
                    st.markdown(text)
                    st.session_state.chat.append({"role": "assistant", "content": text})
                except Exception as e:
                    err = f"ì—ëŸ¬: {e}"
                    st.error(err)
                    st.session_state.chat.append({"role": "assistant", "content": err})

    with st.expander("ì±—ë´‡ ê·¼ê±° ë°ì´í„°(ê²€ì¦ìš©)", expanded=False):
        st.text(retrieval)

    if st.button("ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.chat = [{"role": "assistant", "content": "ëŒ€í™”ë¥¼ ì´ˆê¸°í™”í–ˆì–´ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?"}]
